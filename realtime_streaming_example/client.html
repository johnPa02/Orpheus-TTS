<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Realtime Voice Assistant (Whisper ‚Üí GPT ‚Üí Orpheus)</title>
  <style>
    body { font-family: system-ui, sans-serif; margin: 2rem; line-height: 1.6; }
    h1 { color: #333; }
    textarea { width: 100%; max-width: 40rem; }
    button { margin-top: 0.5rem; padding: 0.5rem 1rem; }
    section { margin-bottom: 3rem; }
    .status { font-family: monospace; color: #666; margin-top: 0.25rem; }
    .transcript { white-space: pre-line; border-left: 3px solid #ccc; padding-left: 0.75rem; }
    audio { margin-top: 1rem; width: 100%; max-width: 40rem; }
  </style>
</head>
<body>
  <h1>üéôÔ∏è Realtime STT ‚Üí LLM ‚Üí TTS Demo</h1>
  <p>Set <code>baseUrl</code> to your Flask server (e.g. <code>http://localhost:8080</code> or your RunPod proxy URL).</p>

  <!-- ==================== TTS Demo ==================== -->
  <section>
    <h2>üó£Ô∏è Text-to-Speech (TTS)</h2>
    <form id="promptForm">
      <label for="promptInput">Enter Prompt:</label><br>
      <textarea id="promptInput" rows="3" placeholder="Type your prompt here..." required></textarea><br>
      <button type="submit">Play Audio</button>
    </form>
    <audio id="ttsAudio" controls></audio>
  </section>

  <!-- ==================== Voice Assistant ==================== -->
  <section>
    <h2>ü§ñ Voice Assistant (Realtime Streaming)</h2>
    <p>Press record, speak, then wait ‚Äî it‚Äôll transcribe your voice, reply with GPT, and stream Orpheus TTS back in real time.</p>
    <button id="recordButton">Start Recording</button>
    <div class="status" id="recordStatus">Idle</div>
    <audio id="assistantAudio" controls></audio>

    <div>
      <h3>User Transcript</h3>
      <p id="userTranscript" class="transcript">‚Äî</p>
    </div>
    <div>
      <h3>Assistant Reply</h3>
      <p id="assistantReply" class="transcript">‚Äî</p>
    </div>
  </section>

  <script>
    const baseUrl = 'https://8cv8jn83kwcr09-8080.proxy.runpod.net'; // change if running locally

    // ---------- üîä TTS Demo ----------
    document.getElementById('promptForm').addEventListener('submit', function (event) {
      event.preventDefault();
      const prompt = document.getElementById('promptInput').value;
      const audioUrl = `${baseUrl}/tts?prompt=${encodeURIComponent(prompt)}&ts=${Date.now()}`;
      const player = document.getElementById('ttsAudio');
      player.src = audioUrl;
      player.play().catch(err => console.error('Playback error:', err));
    });

    // ---------- üé§ Voice Assistant ----------
    const recordButton = document.getElementById('recordButton');
    const recordStatus = document.getElementById('recordStatus');
    const assistantAudio = document.getElementById('assistantAudio');
    const userTranscript = document.getElementById('userTranscript');
    const assistantReply = document.getElementById('assistantReply');

    let mediaRecorder = null;
    let recordedChunks = [];
    let isRecording = false;

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recordedChunks = [];
        const mimeType = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
          ? "audio/webm;codecs=opus"
          : "audio/webm";
        mediaRecorder = new MediaRecorder(stream, { mimeType });

        mediaRecorder.addEventListener('dataavailable', e => {
          if (e.data.size > 0) recordedChunks.push(e.data);
        });
        mediaRecorder.addEventListener('stop', handleRecordingStopRealtime);

        mediaRecorder.start();
        isRecording = true;
        recordButton.textContent = 'Stop Recording';
        recordStatus.textContent = 'Recording‚Ä¶';
      } catch (err) {
        console.error('Microphone access error:', err);
        recordStatus.textContent = 'Microphone permission denied';
      }
    }

    async function stopRecording() {
      if (!mediaRecorder) return;
      mediaRecorder.stop();
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
      isRecording = false;
      recordButton.textContent = 'Start Recording';
      recordStatus.textContent = 'Processing‚Ä¶';
    }

    recordButton.addEventListener('click', () => {
      if (isRecording) stopRecording();
      else startRecording();
    });

    async function handleRecordingStopRealtime() {
      const audioBlob = new Blob(recordedChunks, { type: 'audio/webm;codecs=opus' });
      const formData = new FormData();
      formData.append('audio', audioBlob, 'input.webm');

      try {
        const response = await fetch(`${baseUrl}/voice-assistant-stream?ts=${Date.now()}`, {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          const errorPayload = await response.json().catch(() => ({}));
          throw new Error(errorPayload.error || `Request failed: ${response.status}`);
        }

        // üß† L·∫•y transcript & reply text t·ª´ header
        userTranscript.textContent = response.headers.get('X-Transcript') || '‚Äî';
        assistantReply.textContent = response.headers.get('X-Assistant-Text') || '‚Äî';

        // üéß Ph√°t realtime b·∫±ng Web Audio API
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const reader = response.body.getReader();
        let audioBuffer = [];
        const decoder = async (data) => {
          try {
            const buf = await audioCtx.decodeAudioData(data);
            const src = audioCtx.createBufferSource();
            src.buffer = buf;
            src.connect(audioCtx.destination);
            src.start();
          } catch (e) { /* skip partial */ }
        };

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          if (value) {
            audioBuffer.push(value);
            const blob = new Blob(audioBuffer, { type: 'audio/wav' });
            const arrBuf = await blob.arrayBuffer();
            decoder(arrBuf);
          }
        }

        recordStatus.textContent = 'Done ‚úÖ';
      } catch (err) {
        console.error('Streaming error:', err);
        recordStatus.textContent = err.message;
      } finally {
        mediaRecorder = null;
      }
    }
  </script>
</body>
</html>
